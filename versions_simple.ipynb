{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3,preprocess_input,decode_predictions\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from keras.layers import Dense, GlobalAveragePooling2D,Dropout,Input\n",
    "from keras.layers.advanced_activations import LeakyReLU, ELU\n",
    "import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "from keras.layers.core import Activation, Dense, Lambda\n",
    "import scipy.ndimage\n",
    "from  scipy import ndimage\n",
    "from keras.models import Sequential,Model\n",
    "from keras import backend as K\n",
    "from IPython.display import display\n",
    "from keras.models import Model\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "base_model  = InceptionV3(weights = 'imagenet', include_top=False)\n",
    "print('loaded model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data_gen_args = dict(preprocessing_function=preprocess_input, #Define the dictionary for Image data Generator\n",
    "  #  rotation_range=30,\n",
    "  #  width_shift_range=0.2,\n",
    "  #  height_shift_range=0.2,\n",
    "  #  shear_range=0.2,\n",
    "  #  zoom_range=0.2,\n",
    "  #  horizontal_flip=True,\n",
    "   # vertical_flip = True)\n",
    "\n",
    "#train_datagen = image.ImageDataGenerator(**data_gen_args)\n",
    "#test_datagen = image.ImageDataGenerator(**data_gen_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size= 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set= ('/home/saheed/notebookProj/breakHis/mkfold_keras_8im/fold2/100') \n",
    "                                            \n",
    "test_set =('/home/saheed/notebookProj/breakHis/mkfold_keras_8im/fold2/100')\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19.0\n",
      "1.14.5\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import scipy\n",
    "import pprint\n",
    "import scipy\n",
    "\n",
    "print(scipy.version.version)\n",
    "print(numpy.version.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_201 (Conv2D)          (None, 512, 512, 16)      448       \n",
      "_________________________________________________________________\n",
      "batch_normalization_205 (Bat (None, 512, 512, 16)      64        \n",
      "_________________________________________________________________\n",
      "activation_205 (Activation)  (None, 512, 512, 16)      0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 512, 512, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_202 (Conv2D)          (None, 512, 512, 16)      2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_206 (Bat (None, 512, 512, 16)      64        \n",
      "_________________________________________________________________\n",
      "activation_206 (Activation)  (None, 512, 512, 16)      0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 512, 512, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 256, 256, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_203 (Conv2D)          (None, 256, 256, 32)      4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_207 (Bat (None, 256, 256, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_207 (Activation)  (None, 256, 256, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 256, 256, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_204 (Conv2D)          (None, 256, 256, 32)      9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_208 (Bat (None, 256, 256, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_208 (Activation)  (None, 256, 256, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 256, 256, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_205 (Conv2D)          (None, 128, 128, 64)      18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_209 (Bat (None, 128, 128, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_209 (Activation)  (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_206 (Conv2D)          (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_210 (Bat (None, 128, 128, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_210 (Activation)  (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 262144)            0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               134218240 \n",
      "_________________________________________________________________\n",
      "batch_normalization_211 (Bat (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_211 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 4104      \n",
      "_________________________________________________________________\n",
      "batch_normalization_212 (Bat (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "activation_212 (Activation)  (None, 8)                 0         \n",
      "=================================================================\n",
      "Total params: 134,297,400\n",
      "Trainable params: 134,295,912\n",
      "Non-trainable params: 1,488\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D,MaxPooling2D,Flatten\n",
    "from keras.engine.topology import Layer\n",
    "dropout = .1\n",
    "num_output=8\n",
    "learning_rate = .001\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3, 3), padding='same', input_shape=(512, 512, 3), kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.normalization.BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout))\n",
    "    \n",
    "model.add(Conv2D(16, (3, 3), padding='same', kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.normalization.BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.normalization.BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout))\n",
    "    \n",
    "model.add(Conv2D(32, (3, 3), padding='same', kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.normalization.BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.normalization.BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout))\n",
    "    \n",
    "model.add(Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.normalization.BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, kernel_initializer=\"he_normal\"))\n",
    "model.add(keras.layers.normalization.BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout*5))\n",
    "\n",
    "model.add(Dense(num_output, kernel_initializer=\"he_normal\"))\n",
    "model.add(keras.layers.normalization.BatchNormalization())\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "Adam = keras.optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_train 1461\n",
      "num_valid 620\n",
      "Found 1461 images belonging to 8 classes.\n",
      "Found 620 images belonging to 8 classes.\n",
      "Epoch 1/50\n",
      "91/91 [==============================] - 3263s 36s/step - loss: 1.9544 - acc: 0.3216 - val_loss: 2.0368 - val_acc: 0.1677\n",
      "Epoch 2/50\n",
      "91/91 [==============================] - 3170s 35s/step - loss: 1.9561 - acc: 0.3229 - val_loss: 2.0295 - val_acc: 0.1774\n",
      "Epoch 3/50\n",
      "91/91 [==============================] - 3104s 34s/step - loss: 1.9607 - acc: 0.3122 - val_loss: 2.0423 - val_acc: 0.1758\n",
      "Epoch 4/50\n",
      "91/91 [==============================] - 3110s 34s/step - loss: 1.9536 - acc: 0.3209 - val_loss: 2.0363 - val_acc: 0.1742\n",
      "Epoch 5/50\n",
      "91/91 [==============================] - 3123s 34s/step - loss: 1.9563 - acc: 0.3331 - val_loss: 2.0360 - val_acc: 0.1742\n",
      "Epoch 6/50\n",
      "91/91 [==============================] - 3102s 34s/step - loss: 1.9538 - acc: 0.3389 - val_loss: 2.0345 - val_acc: 0.1919\n",
      "Epoch 7/50\n",
      "91/91 [==============================] - 3122s 34s/step - loss: 1.9589 - acc: 0.3188 - val_loss: 2.0374 - val_acc: 0.1871\n",
      "Epoch 8/50\n",
      "91/91 [==============================] - 3124s 34s/step - loss: 1.9610 - acc: 0.3209 - val_loss: 2.0417 - val_acc: 0.1694\n",
      "Epoch 9/50\n",
      "91/91 [==============================] - 3136s 34s/step - loss: 1.9596 - acc: 0.3052 - val_loss: 2.0415 - val_acc: 0.1645\n",
      "Epoch 10/50\n",
      "91/91 [==============================] - 3159s 35s/step - loss: 1.9563 - acc: 0.3229 - val_loss: 2.0397 - val_acc: 0.1581\n",
      "Epoch 11/50\n",
      "91/91 [==============================] - 3140s 35s/step - loss: 1.9471 - acc: 0.3347 - val_loss: 2.0345 - val_acc: 0.1726\n",
      "Epoch 12/50\n",
      "91/91 [==============================] - 3248s 36s/step - loss: 1.9646 - acc: 0.3262 - val_loss: 2.0352 - val_acc: 0.1694\n",
      "Epoch 13/50\n",
      "91/91 [==============================] - 3158s 35s/step - loss: 1.9525 - acc: 0.3433 - val_loss: 2.0330 - val_acc: 0.1742\n",
      "Epoch 14/50\n",
      "91/91 [==============================] - 3190s 35s/step - loss: 1.9573 - acc: 0.3139 - val_loss: 2.0304 - val_acc: 0.1871\n",
      "Epoch 15/50\n",
      "91/91 [==============================] - 3164s 35s/step - loss: 1.9548 - acc: 0.3342 - val_loss: 2.0435 - val_acc: 0.1645\n",
      "Epoch 16/50\n",
      "91/91 [==============================] - 3167s 35s/step - loss: 1.9633 - acc: 0.3122 - val_loss: 2.0300 - val_acc: 0.1806\n",
      "Epoch 17/50\n",
      "91/91 [==============================] - 3168s 35s/step - loss: 1.9575 - acc: 0.3175 - val_loss: 2.0402 - val_acc: 0.1661\n",
      "Epoch 18/50\n",
      "91/91 [==============================] - 3177s 35s/step - loss: 1.9558 - acc: 0.3341 - val_loss: 2.0393 - val_acc: 0.1629\n",
      "Epoch 19/50\n",
      "91/91 [==============================] - 3157s 35s/step - loss: 1.9561 - acc: 0.3353 - val_loss: 2.0401 - val_acc: 0.1661\n",
      "Epoch 20/50\n",
      "91/91 [==============================] - 3162s 35s/step - loss: 1.9534 - acc: 0.3242 - val_loss: 2.0359 - val_acc: 0.2016\n",
      "Epoch 21/50\n",
      "91/91 [==============================] - 3138s 34s/step - loss: 1.9510 - acc: 0.3474 - val_loss: 2.0296 - val_acc: 0.1984\n",
      "Epoch 22/50\n",
      "91/91 [==============================] - 3171s 35s/step - loss: 1.9573 - acc: 0.3125 - val_loss: 2.0315 - val_acc: 0.1790\n",
      "Epoch 23/50\n",
      "91/91 [==============================] - 3181s 35s/step - loss: 1.9553 - acc: 0.3095 - val_loss: 2.0395 - val_acc: 0.1742\n",
      "Epoch 24/50\n",
      "91/91 [==============================] - 3151s 35s/step - loss: 1.9597 - acc: 0.3223 - val_loss: 2.0316 - val_acc: 0.1742\n",
      "Epoch 25/50\n",
      "91/91 [==============================] - 3102s 34s/step - loss: 1.9569 - acc: 0.3210 - val_loss: 2.0412 - val_acc: 0.1710\n",
      "Epoch 26/50\n",
      "91/91 [==============================] - 3140s 35s/step - loss: 1.9604 - acc: 0.3194 - val_loss: 2.0390 - val_acc: 0.1645\n",
      "Epoch 27/50\n",
      "91/91 [==============================] - 3125s 34s/step - loss: 1.9537 - acc: 0.3210 - val_loss: 2.0304 - val_acc: 0.2016\n",
      "Epoch 28/50\n",
      "91/91 [==============================] - 3167s 35s/step - loss: 1.9574 - acc: 0.3103 - val_loss: 2.0374 - val_acc: 0.1871\n",
      "Epoch 29/50\n",
      "91/91 [==============================] - 3378s 37s/step - loss: 1.9666 - acc: 0.3191 - val_loss: 2.0217 - val_acc: 0.2000\n",
      "Epoch 30/50\n",
      "91/91 [==============================] - 3365s 37s/step - loss: 1.9579 - acc: 0.3381 - val_loss: 2.0362 - val_acc: 0.1677\n",
      "Epoch 31/50\n",
      "91/91 [==============================] - 3182s 35s/step - loss: 1.9572 - acc: 0.3218 - val_loss: 2.0371 - val_acc: 0.1581\n",
      "Epoch 32/50\n",
      "91/91 [==============================] - 3181s 35s/step - loss: 1.9592 - acc: 0.3457 - val_loss: 2.0368 - val_acc: 0.1613\n",
      "Epoch 33/50\n",
      "91/91 [==============================] - 3204s 35s/step - loss: 1.9632 - acc: 0.3336 - val_loss: 2.0400 - val_acc: 0.1613\n",
      "Epoch 34/50\n",
      "91/91 [==============================] - 3212s 35s/step - loss: 1.9575 - acc: 0.3284 - val_loss: 2.0396 - val_acc: 0.1726\n",
      "Epoch 35/50\n",
      "91/91 [==============================] - 3229s 35s/step - loss: 1.9598 - acc: 0.3207 - val_loss: 2.0396 - val_acc: 0.1855\n",
      "Epoch 36/50\n",
      "91/91 [==============================] - 3163s 35s/step - loss: 1.9541 - acc: 0.3253 - val_loss: 2.0376 - val_acc: 0.1694\n",
      "Epoch 37/50\n",
      "91/91 [==============================] - 3197s 35s/step - loss: 1.9605 - acc: 0.3304 - val_loss: 2.0303 - val_acc: 0.1855\n",
      "Epoch 38/50\n",
      "91/91 [==============================] - 3282s 36s/step - loss: 1.9585 - acc: 0.3239 - val_loss: 2.0460 - val_acc: 0.1613\n",
      "Epoch 39/50\n",
      "91/91 [==============================] - 3378s 37s/step - loss: 1.9548 - acc: 0.3263 - val_loss: 2.0399 - val_acc: 0.1645\n",
      "Epoch 40/50\n",
      "91/91 [==============================] - 3992s 44s/step - loss: 1.9567 - acc: 0.3243 - val_loss: 2.0448 - val_acc: 0.1677\n",
      "Epoch 41/50\n",
      "91/91 [==============================] - 4044s 44s/step - loss: 1.9638 - acc: 0.3249 - val_loss: 2.0328 - val_acc: 0.2081\n",
      "Epoch 42/50\n",
      "91/91 [==============================] - 3801s 42s/step - loss: 1.9576 - acc: 0.3224 - val_loss: 2.0503 - val_acc: 0.1774\n",
      "Epoch 43/50\n",
      "91/91 [==============================] - 3939s 43s/step - loss: 1.9527 - acc: 0.3291 - val_loss: 2.0295 - val_acc: 0.1887\n",
      "Epoch 44/50\n",
      "91/91 [==============================] - 4587s 50s/step - loss: 1.9543 - acc: 0.3231 - val_loss: 2.0180 - val_acc: 0.1710\n",
      "Epoch 45/50\n",
      "91/91 [==============================] - 4028s 44s/step - loss: 1.9578 - acc: 0.3142 - val_loss: 2.0342 - val_acc: 0.1629\n",
      "Epoch 46/50\n",
      "91/91 [==============================] - 3918s 43s/step - loss: 1.9573 - acc: 0.3287 - val_loss: 2.0456 - val_acc: 0.1774\n",
      "Epoch 47/50\n",
      "91/91 [==============================] - 4010s 44s/step - loss: 1.9655 - acc: 0.3214 - val_loss: 2.0408 - val_acc: 0.1597\n",
      "Epoch 48/50\n",
      "91/91 [==============================] - 3943s 43s/step - loss: 1.9726 - acc: 0.3102 - val_loss: 2.0460 - val_acc: 0.1645\n",
      "Epoch 49/50\n",
      "91/91 [==============================] - 3854s 42s/step - loss: 1.9558 - acc: 0.3249 - val_loss: 2.0317 - val_acc: 0.1677\n",
      "Epoch 50/50\n",
      "91/91 [==============================] - 3725s 41s/step - loss: 1.9655 - acc: 0.3128 - val_loss: 2.0330 - val_acc: 0.1613\n",
      "Make------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "train_loc = os.path.join(str(train_set), 'train')\n",
    "test_loc = os.path.join(str(test_set), 'test')\n",
    "num_train = len(glob.glob(train_loc + '/**/*.png', recursive=True))\n",
    "num_test = len(glob.glob(test_loc + '/**/*.png', recursive=True))\n",
    "print('num_train', num_train)\n",
    "print('num_valid', num_test)\n",
    "\n",
    "steps_per_epoch = np.floor(num_train/batch_size)\n",
    "validation_steps = np.floor(num_test/batch_size)\n",
    "epochs_fist = 50\n",
    "img_dim = 512\n",
    " # Image generators\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.1,\n",
    "    height_shift_range=.2,\n",
    "    width_shift_range=.2,\n",
    "    rotation_range=360,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)\n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "        train_loc,\n",
    "        target_size=(img_dim, img_dim),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "valid_datagen = ImageDataGenerator( rescale=1./255)\n",
    "\n",
    "valid_generator = datagen.flow_from_directory(\n",
    "        test_loc,\n",
    "        target_size=(img_dim, img_dim),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "predictions = Dense(num_output, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "hist = model.fit_generator(generator,\n",
    "        validation_data=valid_generator,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=epochs_fist,\n",
    "        validation_steps=validation_steps)\n",
    "\n",
    "print('Make------------------')\n",
    "\n",
    "\n",
    "model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
